{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "jupyter: python3\n",
        "from: markdown+emoji\n",
        "execute:\n",
        "  echo: true\n",
        "  eval: false\n",
        "  message: false\n",
        "  warning: false\n",
        "---\n",
        "\n",
        "# Transformations spectrales {#sec-chap03}\n",
        "\n",
        "## :rocket: Préambule\n",
        "Assurez-vous de lire ce préambule avant d'exécutez le reste du notebook.\n",
        "### :dart: Objectifs\n",
        "Dans ce chapitre, nous abordons quelques techniques de réhaussement et de visualisation d'images. Ce chapitre est aussi disponible sous la forme d'un notebook Python:\n",
        "[![](images/colab.png)](https://colab.research.google.com/github/sfoucher/TraitementImagesPythonVol1/blob/main/notebooks/03-TransformationSpectrales.ipynb){target=\"_blank\"} \n",
        "\n",
        "### Librairies\n",
        "Les librairies qui vont être explorées dans ce chapitre sont les suivantes:\n",
        "\n",
        "* [SciPy -](https://scipy.org/)\n",
        "\n",
        "* [NumPy -](https://numpy.org/) \n",
        "\n",
        "* [opencv-python · PyPI](https://pypi.org/project/opencv-python/)\n",
        "\n",
        "* [scikit-image](https://scikit-image.org/)\n",
        "\n",
        "* [Rasterio](https://rasterio.readthedocs.io/en/stable/)\n",
        "\n",
        "* [Xarray](https://docs.xarray.dev/en/stable/)\n",
        "\n",
        "* [rioxarray](https://corteva.github.io/rioxarray/stable/index.html)\n",
        "\n",
        "Dans l'environnement Google Colab, seul `rioxarray` et GDAL doivent être installés:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%capture\n",
        "!apt-get update\n",
        "!apt-get install gdal-bin libgdal-dev\n",
        "!pip install -q rioxarray\n",
        "!pip install -qU \"geemap[workshop]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vérifier les importations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "import numpy as np\n",
        "import rioxarray as rxr\n",
        "from scipy import signal\n",
        "import xarray as xr\n",
        "import xrscipy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Images utilisées\n",
        "\n",
        "Nous allons utilisez les images suivantes dans ce chapitre:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%capture\n",
        "!wget https://github.com/sfoucher/TraitementImagesPythonVol1/raw/refs/heads/main/data/chapitre01/subset_RGBNIR_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903.tif -O RGBNIR_of_S2A.tif\n",
        "!wget https://github.com/sfoucher/opengeos-data/raw/refs/heads/main/raster/landsat7.tif -O landsat7.tif\n",
        "!wget https://github.com/sfoucher/opengeos-data/raw/refs/heads/main/images/berkeley.jpg -O berkeley.jpg\n",
        "!wget https://github.com/sfoucher/TraitementImagesPythonVol1/raw/refs/heads/main/data/chapitre01/subset_1_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903_resampled.tif -O sentinel2.tif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vérifiez que vous êtes capable de les lire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| output: false\n",
        "\n",
        "with rxr.open_rasterio('berkeley.jpg', mask_and_scale= True) as img_rgb:\n",
        "    print(img_rgb)\n",
        "with rxr.open_rasterio('RGBNIR_of_S2A.tif', mask_and_scale= True) as img_rgbnir:\n",
        "    print(img_rgbnir)\n",
        "with rxr.open_rasterio('sentinel2.tif', mask_and_scale= True) as img_s2:\n",
        "    print(img_s2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Qu'est ce que l'information spectrale?\n",
        "\n",
        "L'information spectrale touche à l'exploitation de la dimension spectrale des images (c.à.d le long des bandes spectrales de l'image). La taille de cette dimension spectrale dépend du type de capteurs considéré. Un capteur à très haute résolution spatiale par exemple aura très peu de bandes (4 ou 5). Un capteur multispectral pourra contenir une quinzaine de bande. À l'autre extrême, on trouvera les capteurs hyperspectraux qui peuvent contenir des centaines de bandes spectrales.\n",
        "\n",
        "Pour une surface donnée, la forme des valeurs le long de l'axe spectrale caractérise le type de matériau observé ainsi que son état. On parle souvent alors de signature spectrale. On peut voir celle-ci comme une généralisation de la couleur d'un matériau au delà des bandes visibles du spectre. L'exploitation de ces signatures spectrales est probablement un des principes les plus importants en télédétection qui le distingue de la vison par ordinateur. \n",
        "\n",
        "## Indices spectraux\n",
        "\n",
        "Il existe une vaste littérature sur les indices spectraux, le choix d'un indice plutôt qu'un autre dépend fortement de l'application visée, nous allons simplement couvrir les principes de base ici.\n",
        "\n",
        "Le principe d'un indice spectral consiste à mettre en valeur certaines caractéristiques du spectre comme des pentes, des gradients, etc.\n",
        "\n",
        "## Réduction de dimension\n",
        "\n",
        "La réduction de dimension vise à ne retenir que l'information principale d'un jeu de données. L'objectif est parfois d'éliminer le bruit d'un capteur ou de faciliter la visualisation en ne retenant que 3 bandes principales. Le degré d'information est souvent mesuré par la variance d'une bande, c'est à dire son contraste. L'analyse en composante principale vise alors à ranger l'information contenue dans une image en ordre de variance décroissante.\n",
        "\n",
        "### Analyses en composantes principales\n",
        "\n",
        "L'analyse en composantes principales (ACP) est probablement la plus employée. En théorie, l'ACP n'est valide seulement que sur des données Gaussiennes c'est à dire que le nuage de points des données a la forme d'une ellipse à N dimensions. Cette ellipse est caractérisée par des directions principales (grand axe versus petit axe). La première composante est celle du grand axe de l'ellipse pour laquelle la donnée présente le maximum de variation. L'ACP est une décomposition linéaire, c'est à dire que les composantes principales sont des sommes pondérées des valeurs originales.  \n",
        "\n",
        "## Exercices de révision"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}