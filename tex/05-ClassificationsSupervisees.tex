% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{\textbf{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{french}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={6~ Classifications d'images supervisÃ©es -- Traitement d\textquotesingle images satellites avec Python},
  pdflang={fr},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{6~ Classifications d'images supervisÃ©es -- Traitement
d\textquotesingle images satellites avec Python}
\author{}
\date{}

\begin{document}
\maketitle

\phantomsection\label{quarto-document-content}
\phantomsection\label{title-block-header}
\section{\texorpdfstring{\protect\hypertarget{sec-chap05}{}{{6}~
{Classifications d'images
supervisÃ©es}}}{6~ Classifications d'images supervisÃ©es}}\label{classifications-dimages-supervisuxe9es}

\subsection{\texorpdfstring{{6.1} {ðŸš€}
PrÃ©ambule}{6.1 ðŸš€ PrÃ©ambule}}\label{pruxe9ambule}

Assurez-vous de lire ce prÃ©ambule avant d'exÃ©cutez le reste du notebook.

\subsubsection{\texorpdfstring{{6.1.1} {ðŸŽ¯}
Objectifs}{6.1.1 ðŸŽ¯ Objectifs}}\label{objectifs}

Dans ce chapitre, nous ferons une introduction gÃ©nÃ©rale Ã 
l'apprentissage automatique et abordons quelques techniques
fondamentales. La librairie centrale utilisÃ©e dans ce chapitre sera
\href{https://scikit-learn.org/}{\texttt{sickit-learn}}. Ce chapitre est
aussi disponible sous la forme d'un notebook Python sur Google Colab:

\href{https://colab.research.google.com/github/sfoucher/TraitementImagesPythonVol1/blob/main/notebooks/05-ClassificationsSupervisees.ipynb}{\pandocbounded{\includegraphics[keepaspectratio]{images/colab.png}}}

\subsubsection{\texorpdfstring{{6.1.2}
Librairies}{6.1.2 Librairies}}\label{librairies}

Les librairies utilisÃ©es dans ce chapitre sont les suivantes:

\begin{itemize}
\item
  \href{https://scipy.org/}{SciPy}
\item
  \href{https://numpy.org/}{NumPy}
\item
  \href{https://pypi.org/project/opencv-python/}{opencv-python Â· PyPI}
\item
  \href{https://scikit-image.org/}{scikit-image}
\item
  \href{https://rasterio.readthedocs.io/en/stable/}{Rasterio}
\item
  \href{https://docs.xarray.dev/en/stable/}{xarray}
\item
  \href{https://corteva.github.io/rioxarray/stable/index.html}{rioxarray}
\item
  \href{https://geopandas.org}{geopandas}
\item
  \href{https://scikit-learn.org/}{scikit-learn}
\end{itemize}

Dans l'environnement Google Colab, seul \texttt{rioxarray} et
\texttt{xrscipy} doit Ãªtre installÃ©s:

\phantomsection\label{853d04be}
\phantomsection\label{cb1}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%\%}\NormalTok{capture}
\OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{qU matplotlib rioxarray xrscipy}
\end{Highlighting}
\end{Shaded}

VÃ©rifier les importations nÃ©cessaires en premier:

\phantomsection\label{1e497d69}
\phantomsection\label{cb2}
\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ rioxarray }\ImportTok{as}\NormalTok{ rxr}
\ImportTok{from}\NormalTok{ scipy }\ImportTok{import}\NormalTok{ signal}
\ImportTok{import}\NormalTok{ xarray }\ImportTok{as}\NormalTok{ xr}
\ImportTok{import}\NormalTok{ rasterio}
\ImportTok{import}\NormalTok{ xrscipy}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ matplotlib.colors }\ImportTok{import}\NormalTok{ ListedColormap}
\ImportTok{import}\NormalTok{ geopandas}
\ImportTok{from}\NormalTok{ shapely.geometry }\ImportTok{import}\NormalTok{ Point}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ numba }\ImportTok{import}\NormalTok{ jit}
\ImportTok{from}\NormalTok{ sklearn.neighbors }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ confusion\_matrix, classification\_report, ConfusionMatrixDisplay}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.inspection }\ImportTok{import}\NormalTok{ DecisionBoundaryDisplay}
\ImportTok{from}\NormalTok{ sklearn.discriminant\_analysis }\ImportTok{import}\NormalTok{ LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis}
\ImportTok{from}\NormalTok{ sklearn.datasets }\ImportTok{import}\NormalTok{ make\_blobs, make\_classification, make\_gaussian\_quantiles}
\end{Highlighting}
\end{Shaded}

\subsubsection{\texorpdfstring{{6.1.3} Images
utilisÃ©es}{6.1.3 Images utilisÃ©es}}\label{images-utilisuxe9es}

Nous allons utilisez les images suivantes dans ce chapitre:

\phantomsection\label{c100fc24}
\phantomsection\label{cb3}
\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%\%}\NormalTok{capture}
\ImportTok{import}\NormalTok{ gdown}

\NormalTok{gdown.download(}\StringTok{\textquotesingle{}https://drive.google.com/uc?export=download\&confirm=pbef\&id=1a6Ypg0g1Oy4AJt9XWKWfnR12NW1XhNg\_\textquotesingle{}}\NormalTok{, output}\OperatorTok{=} \StringTok{\textquotesingle{}RGBNIR\_of\_S2A.tif\textquotesingle{}}\NormalTok{)}
\NormalTok{gdown.download(}\StringTok{\textquotesingle{}https://drive.google.com/uc?export=download\&confirm=pbef\&id=1a4PQ68Ru8zBphbQ22j0sgJ4D2quw{-}Wo6\textquotesingle{}}\NormalTok{, output}\OperatorTok{=} \StringTok{\textquotesingle{}landsat7.tif\textquotesingle{}}\NormalTok{)}
\NormalTok{gdown.download(}\StringTok{\textquotesingle{}https://drive.google.com/uc?export=download\&confirm=pbef\&id=1\_zwCLN{-}x7XJcNHJCH6Z8upEdUXtVtvs1\textquotesingle{}}\NormalTok{, output}\OperatorTok{=} \StringTok{\textquotesingle{}berkeley.jpg\textquotesingle{}}\NormalTok{)}
\NormalTok{gdown.download(}\StringTok{\textquotesingle{}https://drive.google.com/uc?export=download\&confirm=pbef\&id=1dM6IVqjba6GHwTLmI7CpX8GP2z5txUq6\textquotesingle{}}\NormalTok{, output}\OperatorTok{=} \StringTok{\textquotesingle{}SAR.tif\textquotesingle{}}\NormalTok{)}
\NormalTok{gdown.download(}\StringTok{\textquotesingle{}https://drive.google.com/uc?export=download\&confirm=pbef\&id=1aAq7crc\_LoaLC3kG3HkQ6Fv5JfG0mswg\textquotesingle{}}\NormalTok{, output}\OperatorTok{=} \StringTok{\textquotesingle{}carte.tif\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

VÃ©rifiez que vous Ãªtes capable de les lire :

\phantomsection\label{baa75366}
\phantomsection\label{cb4}
\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with}\NormalTok{ rxr.open\_rasterio(}\StringTok{\textquotesingle{}berkeley.jpg\textquotesingle{}}\NormalTok{, mask\_and\_scale}\OperatorTok{=} \VariableTok{True}\NormalTok{) }\ImportTok{as}\NormalTok{ img\_rgb:}
    \BuiltInTok{print}\NormalTok{(img\_rgb)}
\ControlFlowTok{with}\NormalTok{ rxr.open\_rasterio(}\StringTok{\textquotesingle{}RGBNIR\_of\_S2A.tif\textquotesingle{}}\NormalTok{, mask\_and\_scale}\OperatorTok{=} \VariableTok{True}\NormalTok{) }\ImportTok{as}\NormalTok{ img\_rgbnir:}
    \BuiltInTok{print}\NormalTok{(img\_rgbnir)}
\ControlFlowTok{with}\NormalTok{ rxr.open\_rasterio(}\StringTok{\textquotesingle{}SAR.tif\textquotesingle{}}\NormalTok{, mask\_and\_scale}\OperatorTok{=} \VariableTok{True}\NormalTok{) }\ImportTok{as}\NormalTok{ img\_SAR:}
    \BuiltInTok{print}\NormalTok{(img\_SAR)}
\ControlFlowTok{with}\NormalTok{ rxr.open\_rasterio(}\StringTok{\textquotesingle{}carte.tif\textquotesingle{}}\NormalTok{, mask\_and\_scale}\OperatorTok{=} \VariableTok{True}\NormalTok{) }\ImportTok{as}\NormalTok{ img\_carte:}
    \BuiltInTok{print}\NormalTok{(img\_carte)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{{6.2} Principes
gÃ©nÃ©raux}{6.2 Principes gÃ©nÃ©raux}}\label{principes-guxe9nuxe9raux}

Une classification supervisÃ©e ou dirigÃ©e consiste Ã  attribuer une
Ã©tiquette (une classe) de maniÃ¨re automatique Ã  chaque point d'un jeu de
donnÃ©es. Cette classification peut se faire Ã  l'aide d'une cascade de
rÃ¨gles prÃ©-Ã©tablies (arbre de dÃ©cision) ou Ã  l'aide de techniques
d'apprentissage automatique (\emph{machine learning}). L'utilisation de
rÃ¨gles prÃ©-Ã©tablies atteint vite une limite car ces rÃ¨gles doivent Ãªtre
fournies manuellement par un expert. Ainsi, l'avantage de
l'apprentissage automatique est que les rÃ¨gles de dÃ©cision sont dÃ©rivÃ©es
automatiquement du jeu de donnÃ©es via une phase dite d'entraÃ®nement. On
parle souvent de solutions gÃ©nÃ©rÃ©es par les donnÃ©es (\emph{Data Driven
Solutions}). Cet ensemble de rÃ¨gles est souvent appelÃ© \textbf{modÃ¨le}.
On visualise souvent ces rÃ¨gles sous la forme de \emph{frontiÃ¨res de
dÃ©cisions} dans l'espace des donnÃ©es. Cependant, un des dÃ©fis majeur de
ce type de technique est d'Ãªtre capable de produire des rÃ¨gles qui
soient gÃ©nÃ©ralisables au-delÃ  du jeu d'entraÃ®nement.

Les classifications supervisÃ©es ou dirigÃ©es prÃ©supposent donc que nous
avons Ã  disposition \textbf{un jeu d'entraÃ®nement} dÃ©jÃ  Ã©tiquetÃ©.
Celui-ci va nous permettre de construire un modÃ¨le. Afin que ce modÃ¨le
soit reprÃ©sentatif et robuste, il nous faut assez de donnÃ©es
d'entraÃ®nement. Les algorithmes d'apprentissage automatique sont trÃ¨s
nombreux et plus ou moins complexes pouvant produire des frontiÃ¨res de
dÃ©cision trÃ¨s complexes et non linÃ©aires.

\textbf{curse of dimensionnality, capacitÃ© d'un modÃ¨le,
sur-aprrentissage, sous-apprentissage}

\subsubsection{\texorpdfstring{{6.2.1} Comportement d'un
modÃ¨le}{6.2.1 Comportement d'un modÃ¨le}}\label{comportement-dun-moduxe8le}

Cet exemple tirÃ© de
\href{https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py}{\texttt{sickit-learn}}
illustre les problÃ¨mes d'ajustement insuffisant ou
\textbf{sous-apprentissage} (\emph{underfitting}) et d'ajustement
excessif ou \textbf{sur-apprentissage} (\emph{overfitting}) et montre
comment nous pouvons utiliser la rÃ©gression linÃ©aire avec un modÃ¨le
polynomiale pour approximer des fonctions non linÃ©aires. La
\hyperref[fig-overfitting]{figure~{6.1}} montre la fonction que nous
voulons approximer, qui est une partie de la fonction cosinus (couleur
orange). En outre, les Ã©chantillons de la fonction rÃ©elle et les
approximations de diffÃ©rents modÃ¨les sont affichÃ©s en bleu. Les modÃ¨les
ont des caractÃ©ristiques polynomiales de diffÃ©rents degrÃ©s. Nous pouvons
constater qu'une fonction linÃ©aire (polynÃ´me de degrÃ© 1) n'est pas
suffisante pour s'adapter aux Ã©chantillons d'apprentissage. C'est ce
qu'on appelle un sous-ajustement (underfitting) qui produit un biais
systÃ©matique quelque soit les points d'entraÃ®nement. Un polynÃ´me de
degrÃ© 4 se rapproche presque parfaitement de la fonction rÃ©elle.
Cependant, pour des degrÃ©s plus Ã©levÃ©s, le modÃ¨le s'adaptera trop aux
donnÃ©es d'apprentissage, c'est-Ã -dire qu'il apprendra le bruit des
donnÃ©es d'apprentissage. Nous Ã©valuons quantitativement le
sur-apprentissage et le sous-apprentissage Ã  l'aide de la validation
croisÃ©e. Nous calculons l'erreur quadratique moyenne (EQM) sur
l'ensemble de validation. Plus elle est Ã©levÃ©e, moins le modÃ¨le est
susceptible de se gÃ©nÃ©raliser correctement Ã  partir des donnÃ©es
d'apprentissage.

\phantomsection\label{cell-fig-overfitting}
\phantomsection\label{fig-overfitting}
\begin{figure}
\centering
\includegraphics[width=11.71875in,height=4.75in]{05-ClassificationsSupervisees_files/figure-html/fig-overfitting-output-1.png}
\caption{Figure~6.1: Exemples de sur et sous-apprentissage.}
\end{figure}

On constate aussi que sans les Ã©chantillons de validation, nous serions
incapable de dÃ©terminer la situation de sur-apprentissage, l'erreur sur
les points d'entraÃ®nement seul Ã©tant excellente pour un degrÃ© 15.

\subsubsection{\texorpdfstring{{6.2.2}
Pipeline}{6.2.2 Pipeline}}\label{pipeline}

La construction d'un modÃ¨le implique gÃ©nÃ©ralement toujours les mÃªmes
Ã©tapes illustrÃ©es sur la figure \hyperref[fig-pipeline]{figure~{6.2}}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  La prÃ©paration des donnÃ©es implique parfois un prÃ©-traitement afin de
  normaliser les donnÃ©es.
\item
  Partage des donnÃ©es en trois groupes: entraÃ®nement, validation et test
\item
  L'apprentissage du modÃ¨le sur l'ensemble d'entraÃ®nement. Cet
  apprentissage nÃ©cessite de dÃ©terminer les valeurs des hyper-paramÃ¨tres
  du modÃ¨le par l'usager.
\item
  La validation du modÃ¨le sur l'ensemble de validation. Cette Ã©tape vise
  Ã  vÃ©rifier que les hyper-paramÃ¨tres du modÃ¨le sont adÃ©quate.
\item
  Enfin le test du modÃ¨le sur un ensemble de donnÃ©e indÃ©pendant
\end{enumerate}

\phantomsection\label{fig-pipeline}
\begin{figure}
\centering
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flowchart TD}
\NormalTok{    A[fa:fa{-}database DonnÃ©es] {-}{-}\textgreater{} B(fa:fa{-}gear PrÃ©traitement)}
\NormalTok{    B {-}{-}\textgreater{} C(fa:fa{-}folder{-}tree Partage des donnÃ©es) {-}.{-}\textgreater{} D(fa:fa{-}gears EntraÃ®nement)}
\NormalTok{    H[[Hyper{-}paramÃ¨tres]] {-}{-}\textgreater{} D}
\NormalTok{    D {-}{-}\textgreater{} |ModÃ¨le| E\textgreater{}Validation]}
\NormalTok{    E {-}{-}\textgreater{} |ModÃ¨le| G\textgreater{}Test]}
\NormalTok{    C {-}.{-}\textgreater{} E}
\NormalTok{    C {-}.{-}\textgreater{} G}
\end{Highlighting}
\end{Shaded}
\caption{Figure~6.2: Ã‰tapes standards dans un entraÃ®nement.}
\end{figure}

\phantomsection\label{sec-05.02.02}
\subsubsection{\texorpdfstring{{6.2.3} Construction d'un ensemble
d'entraÃ®nement}{6.2.3 Construction d'un ensemble d'entraÃ®nement}}\label{construction-dun-ensemble-dentrauxeenement}

Les donnÃ©es d'entraÃ®nement vont permettre de construire un modÃ¨le. Ces
donnÃ©es peuvent prendre des formes trÃ¨s variÃ©es mais on peut voir cela
sous la forme d'un tableau {\textbackslash(N \textbackslash times
D\textbackslash)}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  La taille {\textbackslash(N\textbackslash)} du jeu de donnÃ©e
\item
  Chaque entrÃ©e dÃ©finit un Ã©chantillon ou un point dans un espace Ã 
  plusieurs dimension.
\item
  Chaque Ã©chantillon est dÃ©crit par {\textbackslash(D\textbackslash)}
  dimensions ou caractÃ©ristiques (\emph{features}).
\end{enumerate}

Une faÃ§on simple de construire un ensemble d'entraÃ®nement est
d'Ã©chantillonner un produit existant. Nous allons utiliser la carte
d'occupation des sols suivante qui contient 12 classes diffÃ©rentes.

\phantomsection\label{6b5ba44a}
\phantomsection\label{cb5}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{couleurs\_classes}\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}NoData\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}black\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Commercial\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}yellow\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Nuages\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}lightgrey\textquotesingle{}}\NormalTok{, }
                    \StringTok{\textquotesingle{}Foret\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}darkgreen\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Faible\_vÃ©gÃ©tation\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sol\_nu\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}saddlebrown\textquotesingle{}}\NormalTok{,}
                  \StringTok{\textquotesingle{}Roche\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}dimgray\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Route\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Urbain\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}orange\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Eau\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Tourbe\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}salmon\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}VÃ©gÃ©tation Ã©parse\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}darkgoldenrod\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Roche avec vÃ©gÃ©tation\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}darkseagreen\textquotesingle{}}\NormalTok{\}}
\NormalTok{nom\_classes}\OperatorTok{=}\NormalTok{ [}\OperatorTok{*}\NormalTok{couleurs\_classes.keys()]}
\NormalTok{couleurs\_classes}\OperatorTok{=}\NormalTok{ [}\OperatorTok{*}\NormalTok{couleurs\_classes.values()]}
\end{Highlighting}
\end{Shaded}

On peut visualiser la carte de la faÃ§on suivante:

\phantomsection\label{b7776659}
\phantomsection\label{cb6}
\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ rioxarray }\ImportTok{as}\NormalTok{ rxr}
\NormalTok{cmap\_classes }\OperatorTok{=}\NormalTok{ ListedColormap(couleurs\_classes)}

\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(nrows}\OperatorTok{=}\DecValTok{1}\NormalTok{, ncols}\OperatorTok{=}\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\NormalTok{img\_carte.squeeze().plot.imshow(cmap}\OperatorTok{=}\NormalTok{cmap\_classes, vmin}\OperatorTok{=}\DecValTok{0}\NormalTok{, vmax}\OperatorTok{=}\DecValTok{12}\NormalTok{)}
\NormalTok{ax.set\_title(}\StringTok{"Carte d\textquotesingle{}occupation des sols"}\NormalTok{, fontsize}\OperatorTok{=}\StringTok{"small"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Text(0.5, 1.0, "Carte d'occupation des sols")
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=7.04167in,height=5.65625in]{05-ClassificationsSupervisees_files/figure-html/cell-8-output-2.png}
\caption{}
\end{figure}

On peut facilement calculer la frÃ©quence d'occurrence des 12 classes
dans l'image Ã  l'aide de \texttt{numpy}:

\phantomsection\label{8bff6349}
\phantomsection\label{cb8}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{img\_carte}\OperatorTok{=}\NormalTok{ img\_carte.squeeze() }\CommentTok{\# nÃ©cessaire pour ignorer la dimension du canal}
\NormalTok{compte\_classe }\OperatorTok{=}\NormalTok{ np.unique(img\_carte.data, return\_counts}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(compte\_classe)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(array([ 1.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 11., 12., nan],
      dtype=float32), array([ 193558, 2104777,  670158,   29523,   14624,   94751,  750046,
        123671,    9079,    4327,      10]))
\end{verbatim}

La frÃ©quence d'apparition de chaque classe varie grandement, on parle
alors d'un \textbf{ensemble dÃ©sÃ©quilibrÃ©}. Ceci est trÃ¨s commun dans la
plupart des ensembles d'entraÃ®nement, les classes n'apparaissent pas
avec la mÃªme frÃ©quence.

\phantomsection\label{e7666bf5}
\phantomsection\label{cb10}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{valeurs, comptes }\OperatorTok{=}\NormalTok{ compte\_classe}

\CommentTok{\# Create the histogram}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\NormalTok{plt.bar(valeurs, comptes}\OperatorTok{/}\NormalTok{comptes.}\BuiltInTok{sum}\NormalTok{()}\OperatorTok{*}\DecValTok{100}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Classes"}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{"\%"}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"FrÃ©quences des classes"}\NormalTok{, fontsize}\OperatorTok{=}\StringTok{"small"}\NormalTok{)}
\NormalTok{plt.xticks(}\BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(nom\_classes)), nom\_classes, rotation}\OperatorTok{=}\DecValTok{45}\NormalTok{, ha}\OperatorTok{=}\StringTok{\textquotesingle{}right\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics[width=4.73958in,height=4.38542in]{05-ClassificationsSupervisees_files/figure-html/cell-10-output-1.png}
\caption{}
\end{figure}

On peut Ã©chantillonner 100 points alÃ©atoires pour chaque classe:

\phantomsection\label{fd868584}
\phantomsection\label{cb11}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{img\_carte}\OperatorTok{=}\NormalTok{ img\_carte.squeeze()}
\NormalTok{class\_counts }\OperatorTok{=}\NormalTok{ np.unique(img\_carte.data, return\_counts}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Liste vide des points Ã©chantillonnÃ©es}
\NormalTok{sampled\_points }\OperatorTok{=}\NormalTok{ []}
\NormalTok{class\_labels}\OperatorTok{=}\NormalTok{ [] }\CommentTok{\# contient les Ã©tiquettes des classes}
\ControlFlowTok{for}\NormalTok{ class\_label }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{13}\NormalTok{): }\CommentTok{\# pour chacune des 12 classes}
  \CommentTok{\# On cherche tous les pixels pour cette Ã©tiquette}
\NormalTok{  class\_pixels }\OperatorTok{=}\NormalTok{ np.argwhere(img\_carte.data }\OperatorTok{==}\NormalTok{ class\_label)}

  \CommentTok{\# On se limite Ã  100 pixels par classe}
\NormalTok{  n\_samples }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(}\DecValTok{100}\NormalTok{, }\BuiltInTok{len}\NormalTok{(class\_pixels))}

  \CommentTok{\# On les choisit les positions alÃ©atoirement}
\NormalTok{  np.random.seed(}\DecValTok{0}\NormalTok{) }\CommentTok{\# ceci permet de rÃ©pliquer le tirage alÃ©atoire}
\NormalTok{  sampled\_indices }\OperatorTok{=}\NormalTok{ np.random.choice(}\BuiltInTok{len}\NormalTok{(class\_pixels), n\_samples, replace}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

  \CommentTok{\# On prends les positions en lignes, colonnes}
\NormalTok{  sampled\_pixels }\OperatorTok{=}\NormalTok{ class\_pixels[sampled\_indices]}

  \CommentTok{\# On ajoute les points Ã  la liste}
\NormalTok{  sampled\_points.extend(sampled\_pixels)}
\NormalTok{  class\_labels.extend(np.array([class\_label]}\OperatorTok{*}\NormalTok{n\_samples)[:,np.newaxis])}

\CommentTok{\# Conversion en NumPy array}
\NormalTok{sampled\_points }\OperatorTok{=}\NormalTok{ np.array(sampled\_points)}
\NormalTok{class\_labels }\OperatorTok{=}\NormalTok{ np.array(class\_labels)}
\CommentTok{\# On peut naviguer les points Ã  l\textquotesingle{}aide de la gÃ©orÃ©fÃ©rence}
\NormalTok{transformer }\OperatorTok{=}\NormalTok{ rasterio.transform.AffineTransformer(img\_carte.rio.transform())}
\NormalTok{transform\_sampled\_points}\OperatorTok{=}\NormalTok{ transformer.xy(sampled\_points[:,}\DecValTok{0}\NormalTok{], sampled\_points[:,}\DecValTok{1}\NormalTok{])}

\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(nrows}\OperatorTok{=}\DecValTok{1}\NormalTok{, ncols}\OperatorTok{=}\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\NormalTok{img\_carte.squeeze().plot.imshow(cmap}\OperatorTok{=}\NormalTok{cmap\_classes, vmin}\OperatorTok{=}\DecValTok{0}\NormalTok{, vmax}\OperatorTok{=}\DecValTok{12}\NormalTok{)}
\NormalTok{ax.scatter(transform\_sampled\_points[}\DecValTok{0}\NormalTok{], transform\_sampled\_points[}\DecValTok{1}\NormalTok{], c}\OperatorTok{=}\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{, s}\OperatorTok{=}\DecValTok{1}\NormalTok{)  }\CommentTok{\# Plot sampled points}
\NormalTok{ax.set\_title(}\StringTok{"Carte d\textquotesingle{}occupation des sols avec les points Ã©chantillonnÃ©s"}\NormalTok{, fontsize}\OperatorTok{=}\StringTok{"small"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics[width=7.04167in,height=5.65625in]{05-ClassificationsSupervisees_files/figure-html/cell-11-output-1.png}
\caption{}
\end{figure}

Une fois les points sÃ©lectionnÃ©s, il faut ajouter les valeurs des bandes
provenant d'une image satellite. Pour cela, on peut utiliser la mÃ©thodes
\texttt{sample()} de \texttt{rasterio}. Ã‰ventuellement, la librairie
\href{https://geopandas.org}{\texttt{geopandas}} permet de gÃ©rer les
donnÃ©es d'entraÃ®nement sous la forme d'un tableau transportant aussi
l'information de gÃ©orÃ©fÃ©rence. Afin de pouvoir classifier ces points,
nous allons ajouter les valeurs radiomÃ©triques provenant de l'image
Sentinel-2 Ã  4 bandes \texttt{RGBNIR\_of\_S2A.tif}. Ces valeurs seront
stockÃ©es dans la colonne \texttt{value} sous la forme d'un vecteur en
format \texttt{string}:

\phantomsection\label{e4427311}
\phantomsection\label{cb12}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{points }\OperatorTok{=}\NormalTok{ [Point(xy) }\ControlFlowTok{for}\NormalTok{ xy }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(transform\_sampled\_points[}\DecValTok{0}\NormalTok{], transform\_sampled\_points[}\DecValTok{1}\NormalTok{])]}
\NormalTok{gdf }\OperatorTok{=}\NormalTok{ geopandas.GeoDataFrame(}\BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,}\BuiltInTok{len}\NormalTok{(points)}\OperatorTok{+}\DecValTok{1}\NormalTok{), geometry}\OperatorTok{=}\NormalTok{points, crs}\OperatorTok{=}\NormalTok{img\_carte.rio.crs)}
\NormalTok{coord\_list }\OperatorTok{=}\NormalTok{ [(x, y) }\ControlFlowTok{for}\NormalTok{ x, y }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(gdf[}\StringTok{"geometry"}\NormalTok{].x, gdf[}\StringTok{"geometry"}\NormalTok{].y)]}
\ControlFlowTok{with}\NormalTok{ rasterio.}\BuiltInTok{open}\NormalTok{(}\StringTok{\textquotesingle{}RGBNIR\_of\_S2A.tif\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ src:}
\NormalTok{  gdf[}\StringTok{"value"}\NormalTok{] }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ src.sample(coord\_list)]}
\NormalTok{gdf[}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{]}\OperatorTok{=}\NormalTok{ class\_labels}
\NormalTok{gdf.to\_csv(}\StringTok{\textquotesingle{}sampling\_points.csv\textquotesingle{}}\NormalTok{) }\CommentTok{\# sauvegarde sous forme d\textquotesingle{}un format csv}
\NormalTok{gdf.head()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
& 0 & geometry & value & class \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 & POINT (740369.77 5032078.683) & {[}1894, 1994, 2112, 2318{]} &
1 \\
1 & 2 & POINT (737542.924 5031770.119) & {[}1440, 1650, 1449, 5021{]} &
1 \\
2 & 3 & POINT (736726.722 5031411.786) & {[}1666, 1972, 1819, 3437{]} &
1 \\
3 & 4 & POINT (736816.305 5027470.128) & {[}1858, 2078, 2190, 2436{]} &
1 \\
4 & 5 & POINT (736746.629 5031362.018) & {[}2194, 2304, 2268, 3075{]} &
1 \\
\end{longtable}

\subsection{\texorpdfstring{{6.3} Analyse prÃ©liminaire des
donnÃ©es}{6.3 Analyse prÃ©liminaire des donnÃ©es}}\label{analyse-pruxe9liminaire-des-donnuxe9es}

Une bonne pratique avant d'appliquer une technique d'apprentissage
automatique est de regarder les caractÃ©ristiques de vos donnÃ©es:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Le nombre de dimensions (\emph{features})
\item
  Certaines dimensions sont informatives (discriminantes) et d'autres ne
  le sont pas
\item
  Le nombre classes
\item
  Le nombre de modes (\emph{clusters}) par classes
\item
  Le nombre d'Ã©chantillons par classe
\item
  La forme des groupes
\item
  La sÃ©parabilitÃ© des classes ou des groupes
\end{enumerate}

Une maniÃ¨re d'Ã©valuer la sÃ©parabilitÃ© de vos classes est d'appliquer des
modÃ¨les Gaussiens sur chacune des classes. Le modÃ¨le Gaussien multivariÃ©
suppose que les donnÃ©es sont distribuÃ©es comme un nuage de points
symÃ©trique et unimodale. La distribution d'un point
{\textbackslash(x\textbackslash)} appartenant Ã  la classe
{\textbackslash(i\textbackslash)} est la suivante:

{\textbackslash{[} P(x \textbar{} Classe=i) =
\textbackslash frac\{1\}\{(2\textbackslash pi)\^{}\{D/2\}
\textbar\textbackslash Sigma\_i\textbar\^{}\{1/2\}\}\textbackslash exp\textbackslash left(-\textbackslash frac\{1\}\{2\}
(x-m\_i)\^{}t \textbackslash Sigma\_k\^{}\{-1\}
(x-m\_i)\textbackslash right) \textbackslash{]}}

La mÃ©thode
\href{https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html}{\texttt{QuadraticDiscriminantAnalysis}}
permet de calculer les paramÃ¨tres des Gaussiennes multivariÃ©es pour
chacune des classes.

On peut calculer une distance entre deux nuages Gaussiens avec la
distance dites de Jeffries-Matusita (JM) basÃ©e sur la distance de
Bhattacharyya {\textbackslash(B\textbackslash)}:

{\textbackslash{[} JM\_\{ij\}=
2(1-e\^{}\{-B\})\textbackslash\textbackslash{}
B=\textbackslash frac\{1\}\{8\}(m\_i-m\_j)\^{}t \{
\textbackslash frac\{\textbackslash Sigma\_i+\textbackslash Sigma\_j\}\{2\}
\}(m\_i-m\_j)+\textbackslash frac\{1\}\{2\}ln \{
\textbackslash frac\{\textbar(\textbackslash Sigma\_i+\textbackslash Sigma\_j)/2\textbar\}\{\textbar\textbackslash Sigma\_i\textbar\^{}\{1/2\}\textbar\textbackslash Sigma\_j\textbar\^{}\{1/2\}\}\}
\textbackslash{]}}

Cette distance prÃ©suppose que chaque classe
{\textbackslash(i\textbackslash)} est dÃ©crite par son centre
{\textbackslash(m\_i\textbackslash)} et de sa dispersion dans l'espace Ã 
{\textbackslash(D\textbackslash)} dimensions mesurÃ©e par la matrice de
covariance {\textbackslash(\textbackslash Sigma\_i\textbackslash)}. On
peut en faire facilement une fonction Python Ã  l'aide de \texttt{numpy}:

\phantomsection\label{9caf6a2f}
\phantomsection\label{cb13}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ bhattacharyya\_distance(m1, s1, m2, s2):}
    \CommentTok{\# Calcul de la covariance moyenne}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ (s1 }\OperatorTok{+}\NormalTok{ s2) }\OperatorTok{/} \DecValTok{2}
    
    \CommentTok{\# Calcul du premier terme (diffÃ©rence des moyennes)}
\NormalTok{    m\_diff }\OperatorTok{=}\NormalTok{ m1 }\OperatorTok{{-}}\NormalTok{ m2}
\NormalTok{    term1 }\OperatorTok{=}\NormalTok{ np.dot(np.dot(m\_diff.T, np.linalg.inv(s)), m\_diff) }\OperatorTok{/} \DecValTok{8}
    
    \CommentTok{\# Calcul du second terme (diffÃ©rence de covariances)}
\NormalTok{    term2 }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ np.log(np.linalg.det(s) }\OperatorTok{/}\NormalTok{ np.sqrt(np.linalg.det(s1) }\OperatorTok{*}\NormalTok{ np.linalg.det(s2)))}
    
    \ControlFlowTok{return}\NormalTok{ term1 }\OperatorTok{+}\NormalTok{ term2}

\KeywordTok{def}\NormalTok{ jeffries\_matusita\_distance(m1, s1, m2, s2):}
\NormalTok{    B }\OperatorTok{=}\NormalTok{ bhattacharyya\_distance(m1, s1, m2, s2)}
    \ControlFlowTok{return} \DecValTok{2} \OperatorTok{*}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{B))}
\end{Highlighting}
\end{Shaded}

La figure ci-dessous illustre diffÃ©rentes situations avec des donnÃ©es
artificielles:

\phantomsection\label{3a49cf86}
\begin{figure}
\centering
\includegraphics[width=8.55208in,height=7.71875in]{05-ClassificationsSupervisees_files/figure-html/cell-14-output-1.png}
\caption{}
\end{figure}

On forme notre ensemble d'entrainement Ã  partir du fichier \texttt{csv}
de la section \hyperref[sec-05.02.02]{{Section 6.2.3}}.

\phantomsection\label{084bd8ef}
\phantomsection\label{cb14}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}sampling\_points.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# Extraire la colonne \textquotesingle{}value\textquotesingle{}.}
\CommentTok{\# \textquotesingle{}value\textquotesingle{} est une chaÃ®ne de caractÃ¨res reprÃ©sentation d\textquotesingle{}une liste de nombres.}
\CommentTok{\# Nous devons la convertir en donnÃ©es numÃ©riques rÃ©elles.}
\NormalTok{X }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ x: np.fromstring(x[}\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{], dtype}\OperatorTok{=}\BuiltInTok{float}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)).to\_list()}

\CommentTok{\# on obtient une liste de numpy array  qu\textquotesingle{}il faut convertir en un numpy array 2D}
\NormalTok{X}\OperatorTok{=}\NormalTok{ np.array([row.tolist() }\ControlFlowTok{for}\NormalTok{ row }\KeywordTok{in}\NormalTok{ X])}
\NormalTok{idx}\OperatorTok{=}\NormalTok{ X.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}\OperatorTok{\textgreater{}}\DecValTok{0} \CommentTok{\# on exclut certains points sans valeurs}
\NormalTok{X}\OperatorTok{=}\NormalTok{ X[idx,...]}
\NormalTok{y }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{].to\_numpy()}
\NormalTok{y}\OperatorTok{=}\NormalTok{ y[idx]}
\NormalTok{class\_labels }\OperatorTok{=}\NormalTok{ np.unique(y).tolist() }\CommentTok{\# on cherche Ã  savoir combien de classes uniques}
\NormalTok{n\_classes }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(class\_labels)}
\ControlFlowTok{if} \BuiltInTok{max}\NormalTok{(class\_labels) }\OperatorTok{\textgreater{}}\NormalTok{ n\_classes: }\CommentTok{\# il se peut que certaines classes soit absentes}
\NormalTok{  y\_new}\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ i,l }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(class\_labels):}
\NormalTok{    y\_new.extend([i]}\OperatorTok{*}\BuiltInTok{sum}\NormalTok{(y}\OperatorTok{==}\NormalTok{l))}
\NormalTok{  y\_new }\OperatorTok{=}\NormalTok{ np.array(y\_new)}

\NormalTok{couleurs\_classes2}\OperatorTok{=}\NormalTok{ [couleurs\_classes[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.unique(y).tolist()] }\CommentTok{\# couleurs des classes}
\NormalTok{nom\_classes2}\OperatorTok{=}\NormalTok{ [nom\_classes[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.unique(y).tolist()]}
\NormalTok{cmap\_classes2 }\OperatorTok{=}\NormalTok{ ListedColormap(couleurs\_classes2)}
\end{Highlighting}
\end{Shaded}

On peut faire une analyse de sÃ©parabilitÃ© sur notre ensemble
d'entrainement de 10 classes. On obtient un tableau symmÃ©trique de 10x10
valeurs. On peut observer des valeurs infÃ©rieures Ã  1 ce qui indique des
sÃ©parabilitÃ©s faibles entre ces classes sous l'hypothÃ¨se du modÃ¨le
Gaussien:

\phantomsection\label{c9eea0b8}
\phantomsection\label{cb15}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda}\OperatorTok{=}\NormalTok{ QuadraticDiscriminantAnalysis(store\_covariance}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{qda.fit(X, y\_new) }\CommentTok{\# calcul des paramÃ¨tres des distributions Gaussiennes}
\NormalTok{JM}\OperatorTok{=}\NormalTok{ []}
\NormalTok{classes}\OperatorTok{=}\NormalTok{ np.unique(y\_new).tolist() }\CommentTok{\# Ã©tiquettes uniques des classes}
\ControlFlowTok{for}\NormalTok{ cl1 }\KeywordTok{in}\NormalTok{ classes:}
  \ControlFlowTok{for}\NormalTok{ cl2 }\KeywordTok{in}\NormalTok{ classes:}
\NormalTok{    JM.append(jeffries\_matusita\_distance(qda.means\_[cl1], qda.covariance\_[cl1], qda.means\_[cl2], qda.covariance\_[cl2]))}

\NormalTok{JM}\OperatorTok{=}\NormalTok{ np.array(JM).reshape(}\BuiltInTok{len}\NormalTok{(classes),}\BuiltInTok{len}\NormalTok{(classes))}
\NormalTok{JM}\OperatorTok{=}\NormalTok{ pd.DataFrame(JM, index}\OperatorTok{=}\NormalTok{classes, columns}\OperatorTok{=}\NormalTok{classes)}
\NormalTok{JM.head(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lllllllllll@{}}
\toprule\noalign{}
& 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0.000000 & 1.931891 & 1.809590 & 1.761760 & 1.156486 & 1.326107 &
1.319344 & 1.830671 & 1.873676 & 1.700417 \\
1 & 1.931891 & 0.000000 & 1.082978 & 0.918865 & 1.788737 & 1.527192 &
1.331400 & 1.901749 & 0.854802 & 1.133180 \\
2 & 1.809590 & 1.082978 & 0.000000 & 0.266647 & 1.428062 & 1.255001 &
1.198888 & 1.947302 & 0.193032 & 0.782982 \\
3 & 1.761760 & 0.918865 & 0.266647 & 0.000000 & 1.413401 & 1.219793 &
1.127950 & 1.929637 & 0.377379 & 0.840250 \\
4 & 1.156486 & 1.788737 & 1.428062 & 1.413401 & 0.000000 & 0.397103 &
0.596618 & 1.956182 & 1.517926 & 1.036828 \\
5 & 1.326107 & 1.527192 & 1.255001 & 1.219793 & 0.397103 & 0.000000 &
0.167221 & 1.976696 & 1.248383 & 0.660213 \\
6 & 1.319344 & 1.331400 & 1.198888 & 1.127950 & 0.596618 & 0.167221 &
0.000000 & 1.956804 & 1.207618 & 0.660589 \\
7 & 1.830671 & 1.901749 & 1.947302 & 1.929637 & 1.956182 & 1.976696 &
1.956804 & 0.000000 & 1.966022 & 1.886064 \\
8 & 1.873676 & 0.854802 & 0.193032 & 0.377379 & 1.517926 & 1.248383 &
1.207618 & 1.966022 & 0.000000 & 0.741273 \\
9 & 1.700417 & 1.133180 & 0.782982 & 0.840250 & 1.036828 & 0.660213 &
0.660589 & 1.886064 & 0.741273 & 0.000000 \\
\end{longtable}

Afin d'Ã©valuer chaque classe, on peut calculer la sÃ©parabilitÃ© minimale,
on peut observer que la classe eau a le maximum de sÃ©parabilitÃ© avec les
autres classes.

\phantomsection\label{cff659e5}
\begin{figure}
\centering
\includegraphics[width=4.875in,height=4.38542in]{05-ClassificationsSupervisees_files/figure-html/cell-17-output-1.png}
\caption{}
\end{figure}

\subsection{\texorpdfstring{{6.4} Mesures de performance d'une mÃ©thode
de
classification}{6.4 Mesures de performance d'une mÃ©thode de classification}}\label{mesures-de-performance-dune-muxe9thode-de-classification}

Lorsque que l'on cherche Ã  Ã©tablir la performance d'un modÃ¨le, il faut
Ãªtre capable de mesurer la performance de ce classificateur. Il existe
de nombreuses mesures de performance qui sont toutes dÃ©rivÃ©es de la
matrice de confusion. Cette matrice compare les Ã©tiquettes provenant de
l'annotation (la vÃ©ritÃ© terrain) et les Ã©tiquettes prÃ©dites par un
modÃ¨le. On peut dÃ©finir {\textbackslash(C(i,j)\textbackslash)} est le
nombre de prÃ©dictions dont la vÃ©ritÃ© terrain indique la classe
{\textbackslash(i\textbackslash)} et qui sont prÃ©dites dans la classe
{\textbackslash(j\textbackslash)}. La fonction
\href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html}{confusion\_matrix}
permet de faire ce calcul, voici un exemple trÃ¨s simple:

\phantomsection\label{9ab44e22}
\phantomsection\label{cb16}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ [}\StringTok{"cat"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"bird"}\NormalTok{, }\StringTok{"bird"}\NormalTok{]}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ [}\StringTok{"ant"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"bird"}\NormalTok{]}
\NormalTok{confusion\_matrix(y\_true, y\_pred, labels}\OperatorTok{=}\NormalTok{[}\StringTok{"ant"}\NormalTok{, }\StringTok{"bird"}\NormalTok{, }\StringTok{"cat"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([[2, 0, 0],
       [0, 1, 1],
       [1, 0, 2]])
\end{verbatim}

La fonction
\href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\#sklearn.metrics.classification_report}{classification\_report}
permet de gÃ©nÃ©rer quelques mÃ©triques:

\phantomsection\label{93bf9fab}
\phantomsection\label{cb18}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ [}\StringTok{"cat"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"bird"}\NormalTok{, }\StringTok{"bird"}\NormalTok{]}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ [}\StringTok{"ant"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"ant"}\NormalTok{, }\StringTok{"cat"}\NormalTok{, }\StringTok{"bird"}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(classification\_report(y\_true, y\_pred, target\_names}\OperatorTok{=}\NormalTok{[}\StringTok{"ant"}\NormalTok{, }\StringTok{"bird"}\NormalTok{, }\StringTok{"cat"}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
              precision    recall  f1-score   support

         ant       0.67      1.00      0.80         2
        bird       1.00      0.50      0.67         2
         cat       0.67      0.67      0.67         3

    accuracy                           0.71         7
   macro avg       0.78      0.72      0.71         7
weighted avg       0.76      0.71      0.70         7
\end{verbatim}

Le rappel (\emph{recall}) pour une classe donnÃ©e est la proportion de la
vÃ©ritÃ© terrain qui a Ã©tÃ© correctement identifiÃ©e et est sensible aux
confusions entre classes (erreurs d'omission). Les valeurs de rappels
correspondent Ã  une normalization de la matrice de confusion par rapport
aux lignes.

{\textbackslash{[} Recall\_i= C\_\{ii\} / \textbackslash sum\_j
C\_\{ij\} \textbackslash{]}} Une faible valeur de rappel signifie que le
classificateur confond facilement la classe concernÃ©e avec d'autres
classes.

La prÃ©cision est la portion des prÃ©dictions qui ont Ã©tÃ© bien classifiÃ©es
et est sensible aux fausses alarmes (erreurs de commission). Les valeurs
de prÃ©cision correspondent Ã  une normalization de la matrice de
confusion par rapport aux colonnes. {\textbackslash{[} Precision\_i=
C\_\{ii\} / \textbackslash sum\_i C\_\{ij\} \textbackslash{]}} Une
faible valeur de prÃ©cision signifie que le classificateur trouve
facilement la classe concernÃ©e dans d'autres classes.

Le \texttt{f1-score} calcul une moyenne des deux mÃ©triques prÃ©cÃ©dentes:
{\textbackslash{[}
\textbackslash text\{f1-score\}\_i=2\textbackslash frac\{Recall\_i
\textbackslash times Precision\_i\}\{Recall\_i + Precision\_i\}
\textbackslash{]}}

\subsection{\texorpdfstring{{6.5} MÃ©thodes non
paramÃ©triques}{6.5 MÃ©thodes non paramÃ©triques}}\label{muxe9thodes-non-paramuxe9triques}

Les mÃ©thodes non paramÃ©triques ne font pas d'hypothÃ¨ses particuliÃ¨res
sur les donnÃ©es. Un des inconvÃ©nients de ces modÃ¨les est que le nombre
de paramÃ¨tres du modÃ¨les augmente avec la taille des donnÃ©es.

\phantomsection\label{sec-0511}
\subsubsection{\texorpdfstring{{6.5.1} MÃ©thode des
parallÃ©lÃ©pipÃ¨des}{6.5.1 MÃ©thode des parallÃ©lÃ©pipÃ¨des}}\label{muxe9thode-des-paralluxe9luxe9pipuxe8des}

La mÃ©thode du parallÃ©lÃ©pipÃ¨de est probablement la plus simple et
consiste Ã  dÃ©limiter directement le domaine des points d'une classe par
une boite (un parallÃ©lÃ©pipÃ¨de) Ã  {\textbackslash(D\textbackslash)}
dimensions. Les limites de ces parallÃ©lÃ©pipÃ¨des forment alors des
frontiÃ¨res de dÃ©cision manuelles qui vont permettre dÃ©cider de la classe
d'appartenance d'un nouveau point. Un des avantages de cette technique
est que si un point n'est dans aucun parallÃ©lÃ©pipÃ¨de alors on peut le
laisser comme non classifiÃ©. Par contre, la construction de ces
parallÃ©lÃ©pipÃ¨des se complexifient grandement avec le nombre de bandes. Ã€
une dimension, deux paramÃ¨tres, Ã©quivalents Ã  un seuillage
d'histogramme, sont suffisants. Ã€ deux dimensions, vous devez dÃ©finir 4
segments par classe. Avec 3 bandes, vous devez dÃ©finir 6 plans par
classes et Ã  D dimensions, D hyperplans Ã  D-1 dimensions par classe. Le
modÃ¨le ici est donc une suite de valeurs \texttt{min} et \texttt{max}
pour chacune des bandes et des classes:

\phantomsection\label{7397e81e}
\phantomsection\label{cb20}
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ parrallepiped\_train(X\_train, y\_train):}
\NormalTok{  classes}\OperatorTok{=}\NormalTok{ np.unique(y\_train).tolist()}
\NormalTok{  clf}\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ cl }\KeywordTok{in}\NormalTok{ classes:}
\NormalTok{      data\_cl}\OperatorTok{=}\NormalTok{ X\_train[y\_train }\OperatorTok{==}\NormalTok{ cl,...] }\CommentTok{\# on cherche les donnÃ©es pour la classe courante}
      
\NormalTok{      limits}\OperatorTok{=}\NormalTok{[]}
      \ControlFlowTok{for}\NormalTok{ b }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(data\_cl.shape[}\DecValTok{1}\NormalTok{]):}
\NormalTok{        limits.append([data\_cl[:,b].}\BuiltInTok{min}\NormalTok{(), data\_cl[:,b].}\BuiltInTok{max}\NormalTok{()]) }\CommentTok{\# on calcul le min et max pour chaque bande}
\NormalTok{      clf.append(np.array(limits))}
  \ControlFlowTok{return}\NormalTok{ clf}
\NormalTok{clf}\OperatorTok{=}\NormalTok{ parrallepiped\_train(X, y\_new)}
\end{Highlighting}
\end{Shaded}

La prÃ©diction consiste Ã  trouver pour chaque point la premiÃ¨re limite
qui est satisfaite. Notez qu'il n'y a pas de moyen de dÃ©cider quelle est
la meilleure classe si le point appartient Ã  plusieurs classes.

\phantomsection\label{7c2467dc}
\phantomsection\label{cb21}
\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@jit}\NormalTok{(nopython}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\KeywordTok{def}\NormalTok{ parrallepiped\_predict(clf, X\_test):}
\NormalTok{  y\_pred}\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ data }\KeywordTok{in}\NormalTok{ X\_test:}
\NormalTok{    y\_pred.append(np.nan)}
    \ControlFlowTok{for}\NormalTok{ cl, limits }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(clf):}
\NormalTok{      inside}\OperatorTok{=} \VariableTok{True}
      \ControlFlowTok{for}\NormalTok{ b,limit }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(limits):}
\NormalTok{        inside }\OperatorTok{=}\NormalTok{ inside }\KeywordTok{and}\NormalTok{ (data[b] }\OperatorTok{\textgreater{}=}\NormalTok{ limit[}\DecValTok{0}\NormalTok{]) }\OperatorTok{\&}\NormalTok{ (data[b] }\OperatorTok{\textless{}=}\NormalTok{ limit[}\DecValTok{1}\NormalTok{])}
        \ControlFlowTok{if} \OperatorTok{\textasciitilde{}}\NormalTok{inside:}
          \ControlFlowTok{break}
      \ControlFlowTok{if}\NormalTok{ inside:}
\NormalTok{        y\_pred[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\OperatorTok{=}\NormalTok{cl}
  \ControlFlowTok{return}\NormalTok{ np.array(y\_pred)}
\end{Highlighting}
\end{Shaded}

On peut appliquer ensuite le modÃ¨le sur l'image au complet. Les
rÃ©sultats sont assez mauvais, seule la classe eau en bleu semble Ãªtre
bien classifiÃ©e.

\phantomsection\label{3cb9a268}
\phantomsection\label{cb22}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_image}\OperatorTok{=}\NormalTok{ img\_rgbnir.to\_numpy().transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{).reshape(img\_rgbnir.shape[}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{img\_rgbnir.shape[}\DecValTok{2}\NormalTok{],}\DecValTok{4}\NormalTok{)}
\NormalTok{y\_image}\OperatorTok{=}\NormalTok{ parrallepiped\_predict(clf, data\_image)}
\NormalTok{y\_image}\OperatorTok{=}\NormalTok{ y\_image.reshape(img\_rgbnir.shape[}\DecValTok{1}\NormalTok{],img\_rgbnir.shape[}\DecValTok{2}\NormalTok{])}

\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(nrows}\OperatorTok{=}\DecValTok{1}\NormalTok{, ncols}\OperatorTok{=}\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\NormalTok{plt.imshow(y\_image, cmap}\OperatorTok{=}\NormalTok{cmap\_classes2)}
\NormalTok{ax.set\_title(}\StringTok{"MÃ©thode des parrallÃ©lÃ©pipÃ¨des"}\NormalTok{, fontsize}\OperatorTok{=}\StringTok{"small"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics[width=5.86458in,height=5.45833in]{05-ClassificationsSupervisees_files/figure-html/cell-22-output-1.png}
\caption{}
\end{figure}

On peut calculer quelques mesures de performance sur l'ensemble
d'entrainement:

\phantomsection\label{3ed13b10}
\phantomsection\label{cb23}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_pred}\OperatorTok{=}\NormalTok{ parrallepiped\_predict(clf, X)}
\NormalTok{nom\_classes2}\OperatorTok{=}\NormalTok{ [nom\_classes[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.unique(y).tolist()]}
\BuiltInTok{print}\NormalTok{(classification\_report(y\_new, y\_pred, target\_names}\OperatorTok{=}\NormalTok{nom\_classes2, zero\_division}\OperatorTok{=}\NormalTok{np.nan))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                       precision    recall  f1-score   support

           Commercial       1.00      0.06      0.11       100
                Foret       1.00      0.09      0.17       100
    Faible_vÃ©gÃ©tation       1.00      0.02      0.04       100
               Sol_nu        nan      0.00      0.00       100
                Roche       0.00      0.00      0.00       100
                Route       0.00      0.00      0.00       100
               Urbain       0.08      0.08      0.08       100
                  Eau       0.83      0.88      0.85       100
    VÃ©gÃ©tation Ã©parse       1.00      0.01      0.02       100
Roche avec vÃ©gÃ©tation       0.13      1.00      0.23       100

             accuracy                           0.21      1000
            macro avg       0.56      0.21      0.15      1000
         weighted avg       0.56      0.21      0.15      1000
\end{verbatim}

\paragraph{\texorpdfstring{{6.5.1.1} La malÃ©diction de la haute
dimension}{6.5.1.1 La malÃ©diction de la haute dimension}}\label{la-maluxe9diction-de-la-haute-dimension}

Augmenter le nombre de dimension ou de caractÃ©ristiques des donnÃ©es
permet de rÃ©soudre des problÃ¨mes complexes comme la classification
d'image. Cependant, cela amÃ¨ne beaucoup de contraintes sur le volume des
donnÃ©es. Supposons que nous avons N points occupant un segment linÃ©aire
de taille d.~La densitÃ© de points est
{\textbackslash(N/d\textbackslash)}. Si nous augmentons le nombre de
dimension D, la densitÃ© de points va diminuer exponentiellement en
{\textbackslash(1/d\^{}D\textbackslash)}. Par consÃ©quent, pour garder
une densitÃ© constante et donc une bonne estimation des parallÃ©lÃ©pipÃ¨des,
il nous faudrait augmenter le nombre de points en puissance de D. Ceci
porte le nom de la malÃ©diction de la dimensionnalitÃ©
(\emph{dimensionality curse}). En rÃ©sumÃ©, l'espace vide augmente plus
rapidement que le nombre de donnÃ©es d'entraÃ®nement et l'espace des
donnÃ©es devient de plus en plus parcimonieux (\emph{sparse}). Pour
contrecarrer ce problÃ¨me, on peut sÃ©lectionner les meilleures
caractÃ©ristiques ou appliquer une rÃ©duction de dimension.

\subsubsection{\texorpdfstring{{6.5.2} Plus proches
voisins}{6.5.2 Plus proches voisins}}\label{plus-proches-voisins}

La mÃ©thode des plus proches voisins (\emph{K-Nearest-Neighbors} en
Anglais) est certainement la plus simple des mÃ©thodes pour classifier
des donnÃ©es. Elle consiste Ã  comparer une nouvelle donnÃ©es avec ces
voisins les plus proches en fonction d'une simple distance Euclidienne.
Si une majoritÃ© de ces {\textbackslash(K\textbackslash)} voisins
appartiennent Ã  une classe majoritaire alors cette classe est
sÃ©lectionnÃ©e. Afin de permettre un vote majoritaire, on choisira un
nombre impair pour la valeur de {\textbackslash(K\textbackslash)}.
MallgrÃ© sa simplicitÃ©, cette technique peut devenir assez demandante en
terme de calcul pour un nombre important de points avec un nombre Ã©levÃ©
de dimensions.

Reprensons l'ensemble d'entraÃ®nement formÃ© Ã  partir de notre image
RGBNIR prÃ©cÃ©dente:

\phantomsection\label{4a04f99a}
\phantomsection\label{cb25}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}sampling\_points.csv\textquotesingle{}}\NormalTok{)}
\CommentTok{\# Extraire la colonne \textquotesingle{}value\textquotesingle{}.}
\CommentTok{\# \textquotesingle{}value\textquotesingle{} est une chaÃ®ne de caractÃ¨res comme reprÃ©sentation d\textquotesingle{}une liste de valeurs.}
\CommentTok{\# Nous devons la convertir en donnÃ©es numÃ©riques rÃ©elles.}
\NormalTok{X }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ x: np.fromstring(x[}\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{], dtype}\OperatorTok{=}\BuiltInTok{float}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)).to\_list()}

\CommentTok{\# on obtient une liste de numpy array  qu\textquotesingle{}il faut convertir en un numpy array 2D}
\NormalTok{X}\OperatorTok{=}\NormalTok{ np.array([row.tolist() }\ControlFlowTok{for}\NormalTok{ row }\KeywordTok{in}\NormalTok{ X])}
\NormalTok{idx}\OperatorTok{=}\NormalTok{ X.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}\OperatorTok{\textgreater{}}\DecValTok{0} \CommentTok{\# il se peut qu\textquotesingle{}il y ait des valeurs erronÃ©es}
\NormalTok{X}\OperatorTok{=}\NormalTok{ X[idx,...]}
\NormalTok{y }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{].to\_numpy()}
\NormalTok{y}\OperatorTok{=}\NormalTok{ y[idx]}
\NormalTok{class\_labels }\OperatorTok{=}\NormalTok{ np.unique(y).tolist() }\CommentTok{\# on cherche Ã  savoir combien de classes uniques}
\NormalTok{n\_classes }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(class\_labels)}
\ControlFlowTok{if} \BuiltInTok{max}\NormalTok{(class\_labels) }\OperatorTok{\textgreater{}}\NormalTok{ n\_classes: }\CommentTok{\# il se peut que certaines classes soit absentes}
\NormalTok{  y\_new}\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ i,l }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(class\_labels):}
\NormalTok{    y\_new.extend([i]}\OperatorTok{*}\BuiltInTok{sum}\NormalTok{(y}\OperatorTok{==}\NormalTok{l))}
\NormalTok{  y\_new }\OperatorTok{=}\NormalTok{ np.array(y\_new)}
\NormalTok{nom\_classes2}\OperatorTok{=}\NormalTok{ [nom\_classes[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.unique(y).tolist()]}
\end{Highlighting}
\end{Shaded}

Il est important de faire prÃ©cÃ©der la mÃ©thode K-NN par une normalisation
des donnÃ©es de faÃ§on Ã  ce que chaque caractÃ©ristique soit de moyenne 0
et d'Ã©cart-type Ã©gale Ã  1 (on dit parfois que l'on blanchit les
donnÃ©es). Cette normalisation permet Ã  ce que chaque dimension ait le
mÃªme poids dans le calcul des distances entre points. Cette opÃ©ration
porte le nom de \texttt{StandardScaler} dans \texttt{scikit-learn}. On
peut alors former un pipeline de traitement combinant les deux
opÃ©rations:

\phantomsection\label{770f5604}
\phantomsection\label{cb26}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf }\OperatorTok{=}\NormalTok{ Pipeline(}
\NormalTok{    steps}\OperatorTok{=}\NormalTok{[(}\StringTok{"scaler"}\NormalTok{, StandardScaler()), (}\StringTok{"knn"}\NormalTok{, KNeighborsClassifier(n\_neighbors}\OperatorTok{=}\DecValTok{1}\NormalTok{))]}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Avant d'effectuer un entraÃ®nement, on met gÃ©nÃ©ralement une portion des
donnÃ©es pour valider les performances:

\phantomsection\label{140d8089}
\phantomsection\label{cb27}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y\_new, test\_size}\OperatorTok{=}\FloatTok{0.2}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

On peut visualiser les frontiÃ¨res de dÃ©cision du K-NN pour diffÃ©rentes
valeurs de {\textbackslash(K\textbackslash)} lorsque seulement deux
bandes sont utilisÃ©es (Rouge et proche infra-rouge ici):

\phantomsection\label{bbcea566}
\begin{verbatim}
Number of mislabeled points out of a total 200 points : 143
Number of mislabeled points out of a total 200 points : 141
Number of mislabeled points out of a total 200 points : 136
Number of mislabeled points out of a total 200 points : 130
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=8.125in,height=8.03125in]{05-ClassificationsSupervisees_files/figure-html/cell-27-output-2.png}
\caption{}
\end{figure}

On peut voir comment les diffÃ©rentes frontiÃ¨res de dÃ©cision se forment
dans l'espace des bandes Rouge-NIR. L'augmentation de K rend ces
frontiÃ¨res plus complexes et le calcul plus long.

\phantomsection\label{1417ba18}
\phantomsection\label{cb29}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf.set\_params(knn\_\_weights}\OperatorTok{=}\StringTok{\textquotesingle{}distance\textquotesingle{}}\NormalTok{, knn\_\_n\_neighbors }\OperatorTok{=} \DecValTok{7}\NormalTok{).fit(X\_train, y\_train)}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ clf.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Nombre de points misclassifiÃ©s sur }\SpecialCharTok{\%d}\StringTok{ points : }\SpecialCharTok{\%d}\StringTok{"}
  \OperatorTok{\%}\NormalTok{ (X\_test.shape[}\DecValTok{0}\NormalTok{], (y\_test }\OperatorTok{!=}\NormalTok{ y\_pred).}\BuiltInTok{sum}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Nombre de points misclassifiÃ©s sur 200 points : 117
\end{verbatim}

Le rapport de performance est le suivant:

\phantomsection\label{db22fae5}
\phantomsection\label{cb31}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nom\_classes2}\OperatorTok{=}\NormalTok{ [nom\_classes[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.unique(y).tolist()]}
\BuiltInTok{print}\NormalTok{(classification\_report(y\_test, y\_pred, target\_names}\OperatorTok{=}\NormalTok{nom\_classes2, zero\_division}\OperatorTok{=}\NormalTok{np.nan))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                       precision    recall  f1-score   support

           Commercial       0.38      0.40      0.39        15
                Foret       0.45      0.82      0.58        11
    Faible_vÃ©gÃ©tation       0.29      0.15      0.20        27
               Sol_nu       0.53      0.45      0.49        22
                Roche       0.38      0.26      0.31        23
                Route       0.16      0.17      0.16        18
               Urbain       0.25      0.20      0.22        20
                  Eau       0.96      0.96      0.96        24
    VÃ©gÃ©tation Ã©parse       0.26      0.53      0.35        15
Roche avec vÃ©gÃ©tation       0.40      0.40      0.40        25

             accuracy                           0.41       200
            macro avg       0.40      0.43      0.40       200
         weighted avg       0.42      0.41      0.40       200
\end{verbatim}

La matrice de confusion peut-Ãªtre affichÃ©e de maniÃ¨re graphique:

\phantomsection\label{8b85f6d6}
\phantomsection\label{cb33}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disp}\OperatorTok{=}\NormalTok{ ConfusionMatrixDisplay.from\_predictions(y\_test, y\_pred, display\_labels}\OperatorTok{=}\NormalTok{nom\_classes2, xticks\_rotation}\OperatorTok{=}\StringTok{\textquotesingle{}vertical\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics[width=6.97917in,height=6.17708in]{05-ClassificationsSupervisees_files/figure-html/cell-30-output-1.png}
\caption{}
\end{figure}

L'application du modÃ¨le (la prÃ©diction) peut se faire sur toute l'image
en transposant l'image sous forme d'une matrice avec Largeur x Hauteur
lignes et 4 colonnes:

\phantomsection\label{5122adf1}
\phantomsection\label{cb34}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_image}\OperatorTok{=}\NormalTok{ img\_rgbnir.to\_numpy().transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{).reshape(img\_rgbnir.shape[}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{img\_rgbnir.shape[}\DecValTok{2}\NormalTok{],}\DecValTok{4}\NormalTok{)}
\NormalTok{y\_classe}\OperatorTok{=}\NormalTok{ clf.predict(data\_image)}
\NormalTok{y\_classe}\OperatorTok{=}\NormalTok{ y\_classe.reshape(img\_rgbnir.shape[}\DecValTok{1}\NormalTok{],img\_rgbnir.shape[}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{cf0331af}
\phantomsection\label{cb35}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(nrows}\OperatorTok{=}\DecValTok{1}\NormalTok{, ncols}\OperatorTok{=}\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\NormalTok{plt.imshow(y\_classe, cmap}\OperatorTok{=}\NormalTok{cmap\_classes2)}
\NormalTok{ax.set\_title(}\StringTok{"Carte d\textquotesingle{}occupation des sols avec K{-}NN"}\NormalTok{, fontsize}\OperatorTok{=}\StringTok{"small"}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics[width=5.86458in,height=5.44792in]{05-ClassificationsSupervisees_files/figure-html/cell-32-output-1.png}
\caption{}
\end{figure}

\subsubsection{\texorpdfstring{{6.5.3} MÃ©thodes par arbre de
dÃ©cision}{6.5.3 MÃ©thodes par arbre de dÃ©cision}}\label{muxe9thodes-par-arbre-de-duxe9cision}

La mÃ©thode par arbre de dÃ©cision consiste Ã  contruire une cascade de
rÃ¨gles de dÃ©cision sur chaque caractÃ©ristique du jeu de donnÃ©e. On
pourra trouver plus de dÃ©tails dans la documentation de
\texttt{scikit-learn}
(\href{https://scikit-learn.org/stable/modules/tree.html}{Decision
Trees}). Les arbres de dÃ©cision on tendance Ã  sur-apprendre surtout si
le nombre de dimensions est Ã©levÃ©. Il est donc conseillÃ© d'avoir un bon
ratio entre le nombre d'Ã©chantillons et le nombre de dimensions.

\phantomsection\label{9c65db11}
\phantomsection\label{cb36}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size}\OperatorTok{=}\FloatTok{0.2}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{d53ed433}
\begin{verbatim}
Number of mislabeled points out of a total 200 points : 167
Number of mislabeled points out of a total 200 points : 154
Number of mislabeled points out of a total 200 points : 143
Number of mislabeled points out of a total 200 points : 128
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=8.125in,height=8.03125in]{05-ClassificationsSupervisees_files/figure-html/cell-34-output-2.png}
\caption{}
\end{figure}

On peut observer que les frontiÃ¨res de dÃ©cision sont formÃ©es d'un
ensemble de plans simple. Chaque plan Ã©tant issu d'une rÃ¨gle de dÃ©cison
formÃ© d'un seuil sur chacune des dimensions. On entraine un arbre de
dÃ©cision avec une profondeur maximale de 5:

\phantomsection\label{bc82eb12}
\phantomsection\label{cb38}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf }\OperatorTok{=}\NormalTok{ tree.DecisionTreeClassifier(max\_depth}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{clf.fit(X\_train, y\_train)}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ clf.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Nombre de points misclassifiÃ©s sur }\SpecialCharTok{\%d}\StringTok{ points : }\SpecialCharTok{\%d}\StringTok{"}
  \OperatorTok{\%}\NormalTok{ (X\_test.shape[}\DecValTok{0}\NormalTok{], (y\_test }\OperatorTok{!=}\NormalTok{ y\_pred).}\BuiltInTok{sum}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Nombre de points misclassifiÃ©s sur 200 points : 130
\end{verbatim}

Le rapport de performance et la matrice de confusion:

\phantomsection\label{19ca6084}
\begin{verbatim}
                       precision    recall  f1-score   support

           Commercial       0.37      0.47      0.41        15
                Foret       0.57      0.73      0.64        11
    Faible_vÃ©gÃ©tation       0.19      0.19      0.19        27
               Sol_nu       0.57      0.18      0.28        22
                Roche       0.40      0.09      0.14        23
                Route       0.32      0.44      0.37        18
               Urbain        nan      0.00      0.00        20
                  Eau       0.95      0.79      0.86        24
    VÃ©gÃ©tation Ã©parse        nan      0.00      0.00        15
Roche avec vÃ©gÃ©tation       0.20      0.68      0.31        25

             accuracy                           0.35       200
            macro avg       0.45      0.36      0.32       200
         weighted avg       0.44      0.35      0.31       200
\end{verbatim}

\phantomsection\label{564567a8}
\begin{figure}
\centering
\includegraphics[width=7.125in,height=6.22917in]{05-ClassificationsSupervisees_files/figure-html/cell-37-output-1.png}
\caption{}
\end{figure}

L'application du modÃ¨le (la prÃ©diction) peut se faire sur toute l'image
en transposant l'image sous forme d'une matrice avec Largeur x Hauteur
lignes et 4 colonnes:

\phantomsection\label{11dde5fd}
\begin{figure}
\centering
\includegraphics[width=5.86458in,height=5.45833in]{05-ClassificationsSupervisees_files/figure-html/cell-39-output-1.png}
\caption{}
\end{figure}

Il est possible de visualiser l'arbre mais cela contient beaucoup
d'information

\phantomsection\label{0faafd54}
\phantomsection\label{cb41}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(nrows}\OperatorTok{=}\DecValTok{1}\NormalTok{, ncols}\OperatorTok{=}\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\NormalTok{tree.plot\_tree(clf, max\_depth}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[Text(0.5, 0.8333333333333334, 'x[3] <= 2139.0\ngini = 0.9\nsamples = 800\nvalue = [85, 89, 73, 78, 77, 82, 80, 76, 85, 75]'),
 Text(0.25, 0.5, 'x[2] <= 1714.0\ngini = 0.055\nsamples = 71\nvalue = [0, 0, 0, 0, 1, 0, 0, 69, 0, 1]'),
 Text(0.375, 0.6666666666666667, 'True  '),
 Text(0.125, 0.16666666666666666, '\n  (...)  \n'),
 Text(0.375, 0.16666666666666666, '\n  (...)  \n'),
 Text(0.75, 0.5, 'x[2] <= 1277.0\ngini = 0.89\nsamples = 729\nvalue = [85.0, 89.0, 73.0, 78.0, 76.0, 82.0, 80.0, 7.0, 85.0\n74.0]'),
 Text(0.625, 0.6666666666666667, '  False'),
 Text(0.625, 0.16666666666666666, '\n  (...)  \n'),
 Text(0.875, 0.16666666666666666, '\n  (...)  \n')]
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=6.66667in,height=5.02083in]{05-ClassificationsSupervisees_files/figure-html/cell-40-output-2.png}
\caption{}
\end{figure}

\subsection{\texorpdfstring{{6.6} MÃ©thodes
paramÃ©triques}{6.6 MÃ©thodes paramÃ©triques}}\label{muxe9thodes-paramuxe9triques}

Les mÃ©thodes paramÃ©triques se basent sur des modÃ©lisations statistiques
des donnÃ©es pour permettre une classification. Contraitement au mÃ©thodes
non paramÃ©triques, elles ont un nombre fixe de paramÃ¨tres qui ne dÃ©pend
pas de la taille du jeu de donnÃ©es. Par contre, des hypothÃ¨ses sont
faites sur le comportement statistique des donnÃ©es. La classification
consiste alors Ã  trouver la classe la plus vraisemblable dont le modÃ¨le
statistique dÃ©crit le mieux les valeurs observÃ©es. L'ensemble
d'entraÃ®nement permettra alors de calculer les paramÃ¨tres de chaque
Gaussienne pour chacune des classes d'intÃ©rÃªt.

\subsubsection{\texorpdfstring{{6.6.1} MÃ©thode BayÃ©sienne
naÃ¯ve}{6.6.1 MÃ©thode BayÃ©sienne naÃ¯ve}}\label{muxe9thode-bayuxe9sienne-nauxefve}

La mÃ©thode BayÃ©sienne naÃ¯ve Gaussienne consiste faire des hypothÃ¨ses
simplificatrices sur les donnÃ©es, en particulier l'indÃ©pendance des
donnÃ©es et des dimensions. Ceci permet un calcul plus simple.

\phantomsection\label{72439708}
\phantomsection\label{cb43}
\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.naive\_bayes }\ImportTok{import}\NormalTok{ GaussianNB}
\NormalTok{gnb }\OperatorTok{=}\NormalTok{ GaussianNB()}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ gnb.fit(X\_train, y\_train).predict(X\_test)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Nombre de points erronÃ©s sur }\SpecialCharTok{\%d}\StringTok{ points : }\SpecialCharTok{\%d}\StringTok{"}
      \OperatorTok{\%}\NormalTok{ (X\_test.shape[}\DecValTok{0}\NormalTok{], (y\_test }\OperatorTok{!=}\NormalTok{ y\_pred).}\BuiltInTok{sum}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Nombre de points erronÃ©s sur 200 points : 131
\end{verbatim}

\phantomsection\label{ab0a15ec}
\begin{figure}
\centering
\includegraphics[width=4.08333in,height=4.03125in]{05-ClassificationsSupervisees_files/figure-html/cell-42-output-1.png}
\caption{}
\end{figure}

On peut observer que les frontiÃ¨res de dÃ©cision sont beaucoup plus
rÃ©guliÃ¨res que pour K-NN.

\phantomsection\label{b7a4c105}
\phantomsection\label{cb45}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gnb.fit(X\_train, y\_train)}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ gnb.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Nombre de points misclassifiÃ©s sur }\SpecialCharTok{\%d}\StringTok{ points : }\SpecialCharTok{\%d}\StringTok{"}
  \OperatorTok{\%}\NormalTok{ (X\_test.shape[}\DecValTok{0}\NormalTok{], (y\_test }\OperatorTok{!=}\NormalTok{ y\_pred).}\BuiltInTok{sum}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Nombre de points misclassifiÃ©s sur 200 points : 131
\end{verbatim}

De la mÃªme maniÃ¨re, la prÃ©diction peut s'appliquer sur toute l'image:

\phantomsection\label{29070554}
\begin{figure}
\centering
\includegraphics[width=5.86458in,height=5.45833in]{05-ClassificationsSupervisees_files/figure-html/cell-44-output-1.png}
\caption{}
\end{figure}

\subsubsection{\texorpdfstring{{6.6.2} Analyse Discriminante Quadratique
(ADQ)}{6.6.2 Analyse Discriminante Quadratique (ADQ)}}\label{analyse-discriminante-quadratique-adq}

L'analyse discriminante quadratique peut-Ãªtre vue comme une
gÃ©nÃ©ralisation de l'approche BayÃ©sienne naive qui suppose des modÃ¨les
Gaussiens indÃ©pendants pour chaque dimension et chaque point. Ici, on va
considÃ©rer un modÃ¨le Gaussien multivariÃ©.

\phantomsection\label{cdcbd94f}
\phantomsection\label{cb47}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda }\OperatorTok{=}\NormalTok{ QuadraticDiscriminantAnalysis(store\_covariance}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{qda.fit(X\_train, y\_train)}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ qda.predict(X\_test)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Nombre de points misclassifiÃ©s sur }\SpecialCharTok{\%d}\StringTok{ points : }\SpecialCharTok{\%d}\StringTok{"}
  \OperatorTok{\%}\NormalTok{ (X\_test.shape[}\DecValTok{0}\NormalTok{], (y\_test }\OperatorTok{!=}\NormalTok{ y\_pred).}\BuiltInTok{sum}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Nombre de points misclassifiÃ©s sur 200 points : 124
\end{verbatim}

Les Gaussiennes multivariÃ©es peuvent Ãªtre visualiser sous forme
d'Ã©llipses dÃ©crivant le domaine des valeurs de chaque classe:

\phantomsection\label{19940539}
\begin{figure}
\centering
\includegraphics[width=8.125in,height=3.04167in]{05-ClassificationsSupervisees_files/figure-html/cell-46-output-1.png}
\caption{}
\end{figure}

De la mÃªme maniÃ¨re, la prÃ©diction peut s'appliquer sur toute l'image:

\phantomsection\label{69f47e77}
\begin{figure}
\centering
\includegraphics[width=5.86458in,height=5.45833in]{05-ClassificationsSupervisees_files/figure-html/cell-47-output-1.png}
\caption{}
\end{figure}

\end{document}
